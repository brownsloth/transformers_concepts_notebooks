{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPHjS03x+JouEGeXPcN9o3+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brownsloth/transformers_concepts_notebooks/blob/main/transformers_4_implement_transformer_encoder_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bertviz"
      ],
      "metadata": {
        "id": "U3eo_BxpJWPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
        "import torch\n",
        "from math import sqrt\n",
        "import bertviz"
      ],
      "metadata": {
        "id": "QyfrJSjR4upP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Build the attention head"
      ],
      "metadata": {
        "id": "6epH_X7wJ597"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dYU8wxuVx1l"
      },
      "outputs": [],
      "source": [
        "class AttentionHead(nn.Module):\n",
        "    def __init__(self, embedding_dims, head_dims):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(embedding_dims, head_dims)\n",
        "        self.key = nn.Linear(embedding_dims, head_dims)\n",
        "        self.value = nn.Linear(embedding_dims, head_dims)\n",
        "        self.scale = head_dims ** 0.5\n",
        "\n",
        "    def forward(self, hidden_state):\n",
        "        Q = self.query(hidden_state)\n",
        "        K = self.key(hidden_state)\n",
        "        V = self.value(hidden_state)\n",
        "\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale\n",
        "        weights = torch.softmax(scores, dim=-1)\n",
        "        output = torch.matmul(weights, V)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Build the multi-attention head"
      ],
      "metadata": {
        "id": "-QF1Ij-DJ-Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()  # <- You were missing this\n",
        "\n",
        "        embedding_dims = config.hidden_size\n",
        "        num_heads = config.num_attention_heads\n",
        "        head_dims = embedding_dims // num_heads  # Use integer division\n",
        "\n",
        "        self.heads = nn.ModuleList(\n",
        "            [AttentionHead(embedding_dims=embedding_dims, head_dims=head_dims)\n",
        "             for _ in range(num_heads)]\n",
        "        )\n",
        "        self.output_linear = nn.Linear(embedding_dims, embedding_dims)\n",
        "\n",
        "    def forward(self, hidden_state):\n",
        "        # List of shape (batch, seq_len, head_dim)\n",
        "        head_outputs = [h(hidden_state) for h in self.heads]\n",
        "\n",
        "        # Concatenate along the last dimension to (batch, seq_len, embedding_dim)\n",
        "        concat_output = torch.cat(head_outputs, dim=-1)\n",
        "\n",
        "        output = self.output_linear(concat_output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "gawlJsCf7mgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Lets test the dimensions using some config\n",
        "sentence = 'Hi my name is Tarun and I like to read books.'\n",
        "ckpt = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(ckpt)\n",
        "config = AutoConfig.from_pretrained(ckpt)\n",
        "\n",
        "\n",
        "tokens = tokenizer(sentence, return_tensors='pt', add_special_tokens=False)\n",
        "input_embedding_layer = nn.Embedding(config.vocab_size, config.hidden_size)\n",
        "input_embeddings = input_embedding_layer(tokens.input_ids)\n",
        "multihead_attn = MultiHeadAttention(config)\n",
        "attn_output = multihead_attn(input_embeddings)\n",
        "print(attn_output)\n",
        "print(attn_output.shape)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ov1IoHZY_y4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bertviz import head_view\n",
        "\n",
        "model = AutoModel.from_pretrained(ckpt, output_attentions=True)\n",
        "\n",
        "sentence_a = \"You can call me Tarun.\"\n",
        "sentence_b = \"Please give me a call tomorrow morning.\"\n",
        "\n",
        "viz_inputs = tokenizer(sentence_a, sentence_b, return_tensors='pt')\n",
        "attentions = model(**viz_inputs).attentions\n",
        "\n",
        "sentence_b_start = (viz_inputs.token_type_ids == 0).sum(dim=1)\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(viz_inputs.input_ids[0])\n",
        "\n",
        "head_view(attentions, tokens, sentence_b_start, heads=[11])"
      ],
      "metadata": {
        "id": "IkaAIjh07h0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Build the feed-forward/MLP part"
      ],
      "metadata": {
        "id": "3eCU2GXJKDfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.linear1  = nn.Linear(config.hidden_size, config.intermediate_size)\n",
        "    self.linear2  = nn.Linear(config.intermediate_size, config.hidden_size)\n",
        "\n",
        "    self.gelu = nn.GELU()\n",
        "\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear1(x)\n",
        "    x = self.gelu(x)\n",
        "    x = self.linear2(x)\n",
        "    x = self.dropout(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "5TndNJbUQLg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ff_layer = FeedForward(config)\n",
        "ff_out = ff_layer(attn_output)\n",
        "\n",
        "ff_out.size()"
      ],
      "metadata": {
        "id": "F51Ulf74RAK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Build the encoder layer"
      ],
      "metadata": {
        "id": "C4DvqxDgKLgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderLayer(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.layer_norm_1 = nn.LayerNorm(config.hidden_size)\n",
        "    self.layer_norm_2 = nn.LayerNorm(config.hidden_size)\n",
        "    self.attention = MultiHeadAttention(config)\n",
        "    self.feed_forward = FeedForward(config)\n",
        "\n",
        "  def forward(self, x):\n",
        "    hidden_state = self.layer_norm_1(x)\n",
        "    x = x + self.attention(hidden_state)\n",
        "    x = x + self.feed_forward(self.layer_norm_2(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "2o6R-BX6KKnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_layer = TransformerEncoderLayer(config)\n",
        "input_embeddings.shape, encoder_layer(input_embeddings).size()"
      ],
      "metadata": {
        "id": "EEnEldJ6Llb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\"My name is Tarun and I called Sushila!\", return_tensors='pt', add_special_tokens=False)\n",
        "inputs.input_ids"
      ],
      "metadata": {
        "id": "i9hgQdcVT4re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import embedding\n",
        "\n",
        "class Embeddings(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.token_embeddings = nn.Embedding(config.vocab_size, config.hidden_size)\n",
        "    self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
        "    self.layer_norm = nn.LayerNorm(config.hidden_size, eps=1e-12)\n",
        "    self.dropout = nn.Dropout()\n",
        "\n",
        "  def forward(self, input_ids):\n",
        "    seq_length = input_ids.size(1)\n",
        "    position_ids = torch.arange(end=seq_length, dtype=torch.long).unsqueeze(0)\n",
        "    token_embeddings = self.token_embeddings(input_ids)\n",
        "    position_embeddings = self.position_embeddings(position_ids)\n",
        "    embeddings = token_embeddings + position_embeddings\n",
        "    embeddings_normed = self.layer_norm(embeddings)\n",
        "    embeddings_normed_dropout = self.dropout(embeddings_normed)\n",
        "    return embeddings_normed_dropout"
      ],
      "metadata": {
        "id": "GNscOqehNcAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = Embeddings(config)\n",
        "embedding_layer(inputs.input_ids).size()"
      ],
      "metadata": {
        "id": "vMjlC8sOQAoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Transformer Encoder with all layers"
      ],
      "metadata": {
        "id": "4SbNn3ucQfIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.embeddings = Embeddings(config)\n",
        "    self.layers = nn.ModuleList([TransformerEncoderLayer(config) for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embeddings(x)\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ikU52nzLSL71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = TransformerEncoder(config)\n",
        "encoder(inputs.input_ids).size()"
      ],
      "metadata": {
        "id": "C2DHGqcqS2SU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Add task specific head"
      ],
      "metadata": {
        "id": "HWPHAUylQtp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBasedSequenceClassifier(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.encoder = TransformerEncoder(config)\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "    self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)[:, 0, :] #select hidden state of the [CLS] token\n",
        "    x = self.dropout(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "config.num_labels = 3\n",
        "cls = TransformerBasedSequenceClassifier(config)\n",
        "cls(inputs.input_ids).size()"
      ],
      "metadata": {
        "id": "ykklhGIKQs10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cls(inputs.input_ids)"
      ],
      "metadata": {
        "id": "emIx1F2WVBQx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}